{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e67013-05cf-49bb-9e7a-0765501fe7db",
   "metadata": {},
   "source": [
    "# VAE for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f32d8-ac84-448c-a851-06672230a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AEML import AEML\n",
    "import torch\n",
    "from torch import nn\n",
    "from VAEBase import VAEBase\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e6ec4-9500-43db-92ad-4ef04f8cb9aa",
   "metadata": {},
   "source": [
    "First, download our data to `./data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc67c14-1fe6-4199-9e15-5289aadfb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.utils.data.DataLoader(\n",
    "    tv.datasets.MNIST('./data', download=True,\n",
    "                      transform=tv.transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed0c04a-a32f-4f62-ba1e-5999dcfeb3e7",
   "metadata": {},
   "source": [
    "`VAENormal` is a base class of all our variational autoencoders. Write your code between the three pairs of `YOUR CODE HERE` comments.\n",
    "\n",
    "- `VAENormal.forward()` receives an input image `x`, `enc_...()`odes it, etc., and returns the result of `self.dec()`.\n",
    "- `BernoulliLoss.__call__()` returns the scalar loss associated with the generated Bernoulli parameter array `xz` and the input image `x`.\n",
    "\n",
    "Both methods actually receive a *batch* of images in the form of a `torch.Tensor` whose first dimension runs over the instances. Except for the computation of the scalar end result of the loss function, your code should hardly have to care; it should mostly read like it receives individual images.\n",
    "\n",
    "The same solution should work for all exercises.\n",
    "\n",
    "Finally,\n",
    "\n",
    "- the `VAE` class must be implemented with a suitable network architecture further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1aef4-ed8f-469e-8529-e530371acb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAENormal(VAEBase):\n",
    "    def __init__(self, enc_mu, enc_logsigma, dec):\n",
    "        super(VAENormal, self).__init__()\n",
    "        self.distrib_pz = torch.distributions.Normal(0, 1) # q(z|x), p(z)\n",
    "        self.enc_mu = enc_mu\n",
    "        self.enc_logsigma = enc_logsigma\n",
    "        self.dec = dec\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        ### BEGIN YOUR CODE HERE\n",

    "        ### END YOUR CODE HERE\n",
    "\n",
    "    def encode_mu(self, x):\n",
    "        return self.enc_mu(nn.Flatten()(x))\n",
    "\n",
    "\n",
    "class BernoulliLoss: # p(x|z) is Bernoulli; q(z|x) and p(z) are Normal\n",
    "    def __init__(self, vae):\n",
    "        self.vae = vae\n",
    "        self.BCE = nn.BCELoss(reduction='none')\n",
    "\n",
    "    def __call__(self, xz, x):\n",
    "        ### BEGIN YOUR CODE HERE\n",

    "        ### END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccde81-5d4c-4a36-9f75-e1a761d7527d",
   "metadata": {},
   "source": [
    "Define your VAE encoder and decoder networks, and generate an instance.\n",
    "\n",
    "If you want to use a feature extractor that is common to both the $\\mu$ and $\\log\\sigma$ parts of the encoder, you can avoid altering the `VAENormal` base class by overriding its `forward()` (calling `super().forward(self.enc_...(...))`) and `encode_mu()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3eafc3-f678-4bf1-9c1a-6d5823c93eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdim = 2\n",
    "\n",
    "class VAE(VAENormal):\n",
    "    ### BEGIN YOUR CODE HERE\n",

    "    ### END YOUR CODE HERE\n",
    "\n",
    "\n",
    "model = VAE()\n",
    "# model.load('VAE-MNIST')\n",
    "ml = AEML(data, model, BernoulliLoss(model),\n",
    "          torch.optim.Adam(model.parameters(), lr=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f4169-396e-4ded-89aa-7198fc208641",
   "metadata": {},
   "source": [
    "Now train the model. Call this cell repeatedly if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d70d3-db3d-4dea-912a-4da7c54c36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.run(10)\n",
    "#model.save('VAE-MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e11562-6a22-43d3-ae89-e21da6a9d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load('VAE-MNIST')\n",
    "ml.plotEncDataset()\n",
    "model.plotDecRandom(zdim)\n",
    "model.plotDecGrid(zdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d154df-1931-49c2-82e2-55fc31e36fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
